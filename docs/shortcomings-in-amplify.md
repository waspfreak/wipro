# Shortcomings in Amplify

Amplify is a platform offered by AWS to automate some of the tasks of a serverless application, ranging from GraphQL APIs to hosting, passing through AWS lambda functions, authentications, and AI capabilities.

Unfortunately, it feels that this AWS service has a signficant set of rough edges that we've encountered both while developing our [Proof of Concept(PoC)](https://bitbucket.org/tigerspike/lon-oneweb-onetask-poc/src/master/), and when going for a more robust production implementation.

This document gathers our learnings and findings while working with it so we have a clear view of how well we can rely on it or not.

## Issues found

* Amplify works great for a simple CRUD application, but upon wanting to add bespoke logic on the backend, a lot of boilerplate code is required to break free of its limitations.
  * E.g. The schema.graphql file will require us to manually roll out many types that were autogenerated when we add custom Lambda functions to ensure data integrity.
  * We will need bespoke logic in the backend often. Things as simple as verifying that there's at least a topic member before deletion will introduce significant boilerplate code and testing effort.
* Amplify push seems to be finicky, and in some scenarios has forced us to delete the whole stack to be able to update. Such a scenario occuring in production would either come at a great effort to correct, or infer a data loss.
* Amplify push appears not to do anything from time to time, providing zero context into what's going wrong, and eventually failing with this error log:
  * An error occured during the push operation: Your socket connection to the server was not read from or written to within the timeout period. Idle connections will be closed.
* Amplify mock creates a local DynamoDB database so as to be able to test AWS Lambda functions that interact with DynamoDB, however, it will not populate it with the tables that are generated in the cloud. There's no easy way to automatically create them in our part either. This difficults testing.
* We spent >2 days on getting the frontend in a separate repository to talk to the backend as there's no clear documentation on the actions you can run in amplify (amplify pull was introduced very recently in AWS RE:Invent and was barely documented).
* Some options are not fully automated and required us to create scripts so that we can automate it. E.g. deleting an environment so we can spin up a new one, test and then delete it.
* Frontend code relies on files that are not committed and we are worried about how it will impact the CI pipeline.
* Integrating with ActiveDirectory required to stop using Amplify and rely straight on Cognito. Later, we had to integrate amplify with this custom cognito service, which adds more burden.

## Community perception

The community has already been outspoken in Github on issues found in the system.

It currently has [>400 open issues](https://github.com/aws-amplify/amplify-cli/issues?q=is%3Aissue+is%3Aopen+sort%3Acomments-desc), and amongst them, users raise concern on the [viability of Amplify as a production service](https://github.com/aws-amplify/amplify-cli/issues/1406). Some messages in an open issue since May are here:

> ... Thus far I've resolved these by deleting and recreating the API+DB, but in production that would not be an option. I have no idea how I could perform the updates if we already had a production system. We're now seriously considering can we proceed to production using Amplify or do we need to switch to other solutions.

- - -

> ... We're into the Amplify stack but I'm currently thinking if there is a way we can extricate ourselves out and possibly just use AppSync and bypass Amplify ...

- - -

> ...This is really critical. The amplify push seems very fragile ...

- - -

> ... However, the current state of amplify api push feels like an alpha or beta version because it breaks so frequently and the error messages are nonexistant ...

- - -

> ... I have frankly say that unfortunately this is becoming a really nasty issue for my company, we are going in production very soon and no matter what i do at the moment i cannot fix it, i have to do the api again, and this really scary me in a prod scenario ...

- - -

> I don't understand how people say that amplify is production ready when something as basic as schema "migration" appears to be such a problem.

The discussion above is supposed to have been addressed yet it remains open and recreating the whole stack is something we had to do during the development of the PoC.

The issue seems to be one of the most important ones to resolve on AWS side, as it ranks as the 2nd with most comments, behind a Request For Changes (RFC). It has unfortunately been open for more than half a year.

## Github issues analysis

Based on this [analysis](https://9-volt.github.io/bug-life/?repo=aws-amplify/amplify-cli), we can conclude that:

* Bugs tend to be taken care of promptly. Rarely do they live for multiple months.
* Most of old issues seem to be feature requests, which do look like they are served less promptly.

Another analysis we can use is [Github's pulse](https://github.com/aws-amplify/amplify-cli/pulse/monthly) over the last month:

* 116 closed issues
* 69 new issues

This means that although there's 4 PRs closed per day on average, half of that productivity will be consumed by the new issues raised by users.
